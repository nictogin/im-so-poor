{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter #counting no. of elements in a list and return a dictionary\n",
    "from scipy.sparse import lil_matrix\n",
    "import math\n",
    "from sklearn.preprocessing import normalize #normalize the vectorized 'sentence'/'word'\n",
    "import numpy as np \n",
    "\n",
    "corpus = ['this is the first document',\n",
    "          'this document is the second document',\n",
    "          'and this is the third one',\n",
    "          'is this the first document'] \n",
    "\n",
    "\n",
    "def IDF(corpus, unique_words):\n",
    "    idf_dict={}\n",
    "    N=len(corpus)\n",
    "    \n",
    "    for i in unique_words:\n",
    "        count=0\n",
    "        for sen in corpus:\n",
    "            if i in sen.split():\n",
    "                count=count+1\n",
    "                \n",
    "            idf_dict[i]=(math.log((1+N)/(count+1)))+1\n",
    "    return idf_dict\n",
    "\n",
    "def fit(whole_data):\n",
    "    unique_words = set()\n",
    "    if isinstance(whole_data, (list,)):\n",
    "        for x in whole_data:\n",
    "            for y in x.split():\n",
    "                if len(y)<2:\n",
    "                    continue\n",
    "                unique_words.add(y)\n",
    "        unique_words = sorted(list(unique_words))\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "        Idf_values_of_all_unique_words=IDF(whole_data,unique_words)\n",
    "    return vocab, Idf_values_of_all_unique_words\n",
    "Vocabulary, idf_of_vocabulary=fit(corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(list(Vocabulary.keys()))\n",
    "print(list(idf_of_vocabulary.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the', 'document', 'second', 'one', 'and', 'first', 'this', 'third', 'is'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': 1.0,\n",
       " 'document': 1.2231435513142097,\n",
       " 'second': 1.916290731874155,\n",
       " 'one': 1.916290731874155,\n",
       " 'and': 1.916290731874155,\n",
       " 'first': 1.5108256237659907,\n",
       " 'this': 1.0,\n",
       " 'third': 1.916290731874155,\n",
       " 'is': 1.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set()\n",
    "if isinstance(corpus, (list,)):\n",
    "    for x in corpus:\n",
    "        for y in x.split():\n",
    "            unique_words.add(y)\n",
    "print(unique_words)\n",
    "IDF(corpus,unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM FORM\n",
      "   (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n",
      "  (1, 1)\t0.6876235979836937\n",
      "  (1, 3)\t0.2810886740337529\n",
      "  (1, 5)\t0.5386476208856762\n",
      "  (1, 6)\t0.2810886740337529\n",
      "  (1, 8)\t0.2810886740337529\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (3, 1)\t0.4697913855799205\n",
      "  (3, 2)\t0.580285823684436\n",
      "  (3, 3)\t0.3840852409148149\n",
      "  (3, 6)\t0.3840852409148149\n",
      "  (3, 8)\t0.3840852409148149\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "def transform(dataset,vocabulary,idf_values):\n",
    "    sparse_matrix= lil_matrix( (len(dataset), len(vocabulary)), dtype=np.float64)\n",
    "    for row  in range(0,len(dataset)):\n",
    "        number_of_words_in_sentence=Counter(dataset[row].split())\n",
    "        for word in dataset[row].split():\n",
    "            if word in  list(vocabulary.keys()):\n",
    "                tf_idf_value=(number_of_words_in_sentence[word]/len(dataset[row].split()))*(idf_values[word])\n",
    "                sparse_matrix[row,vocabulary[word]]=tf_idf_value\n",
    "    print(\"NORM FORM\\n\",normalize(sparse_matrix, norm='l2', axis=1, copy=True,return_norm=False))\n",
    "    output = normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "    return output\n",
    "final_output = transform(corpus,Vocabulary,idf_of_vocabulary)\n",
    "print(final_output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "print(final_output[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lil matrix, crc matrix, vector space model\n",
    "\n",
    "https://analyticsindiamag.com/hands-on-implementation-of-tf-idf-from-scratch-in-python/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalization\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
